{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f266922",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:45.780331Z",
     "iopub.status.busy": "2022-02-20T14:52:45.776706Z",
     "iopub.status.idle": "2022-02-20T14:52:46.884343Z",
     "shell.execute_reply": "2022-02-20T14:52:46.886755Z",
     "shell.execute_reply.started": "2022-02-20T14:16:05.931606Z"
    },
    "papermill": {
     "duration": 1.136007,
     "end_time": "2022-02-20T14:52:46.887231",
     "exception": false,
     "start_time": "2022-02-20T14:52:45.751224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ubiquant-market-prediction/example_sample_submission.csv\n",
      "/kaggle/input/ubiquant-market-prediction/example_test.csv\n",
      "/kaggle/input/ubiquant-market-prediction/train.csv\n",
      "/kaggle/input/ubiquant-market-prediction/ubiquant/competition.cpython-37m-x86_64-linux-gnu.so\n",
      "/kaggle/input/ubiquant-market-prediction/ubiquant/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ccc2822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:46.934531Z",
     "iopub.status.busy": "2022-02-20T14:52:46.933329Z",
     "iopub.status.idle": "2022-02-20T14:52:46.936457Z",
     "shell.execute_reply": "2022-02-20T14:52:46.935830Z",
     "shell.execute_reply.started": "2022-02-20T14:16:05.944006Z"
    },
    "papermill": {
     "duration": 0.032612,
     "end_time": "2022-02-20T14:52:46.936624",
     "exception": false,
     "start_time": "2022-02-20T14:52:46.904012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype.name\n",
    "\n",
    "        if col_type not in ['object', 'category', 'datetime64[ns, UTC]']:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94da267b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:46.973493Z",
     "iopub.status.busy": "2022-02-20T14:52:46.972748Z",
     "iopub.status.idle": "2022-02-20T14:52:46.975314Z",
     "shell.execute_reply": "2022-02-20T14:52:46.974778Z",
     "shell.execute_reply.started": "2022-02-20T14:16:05.960864Z"
    },
    "papermill": {
     "duration": 0.022723,
     "end_time": "2022-02-20T14:52:46.975464",
     "exception": false,
     "start_time": "2022-02-20T14:52:46.952741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dtypes = [f'f_{i}' for i in range(300)]\n",
    "# data_types_dict = {\n",
    "#     'time_id': 'int16',\n",
    "#     'investment_id': 'int16',\n",
    "#     'target': 'float16',\n",
    "# }\n",
    "\n",
    "# for f in dtypes:\n",
    "#     data_types_dict[f] = 'float16'\n",
    "    \n",
    "# test_data_types_dict = {\n",
    "#     'time_id': 'int16',\n",
    "#     'investment_id': 'int16'\n",
    "# }\n",
    "\n",
    "# for f in dtypes:\n",
    "#     test_data_types_dict[f] = 'float16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d7d51d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:47.012169Z",
     "iopub.status.busy": "2022-02-20T14:52:47.011221Z",
     "iopub.status.idle": "2022-02-20T14:52:47.013203Z",
     "shell.execute_reply": "2022-02-20T14:52:47.013647Z",
     "shell.execute_reply.started": "2022-02-20T14:16:05.973568Z"
    },
    "papermill": {
     "duration": 0.022964,
     "end_time": "2022-02-20T14:52:47.013825",
     "exception": false,
     "start_time": "2022-02-20T14:52:46.990861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", usecols = data_types_dict.keys(),\n",
    "#                        dtype=data_types_dict)\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75293060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:47.049539Z",
     "iopub.status.busy": "2022-02-20T14:52:47.047728Z",
     "iopub.status.idle": "2022-02-20T14:52:47.051918Z",
     "shell.execute_reply": "2022-02-20T14:52:47.052367Z",
     "shell.execute_reply.started": "2022-02-20T14:16:05.987655Z"
    },
    "papermill": {
     "duration": 0.023359,
     "end_time": "2022-02-20T14:52:47.052555",
     "exception": false,
     "start_time": "2022-02-20T14:52:47.029196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "902a2512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:47.088649Z",
     "iopub.status.busy": "2022-02-20T14:52:47.087925Z",
     "iopub.status.idle": "2022-02-20T14:52:47.090841Z",
     "shell.execute_reply": "2022-02-20T14:52:47.090364Z",
     "shell.execute_reply.started": "2022-02-20T14:16:05.996064Z"
    },
    "papermill": {
     "duration": 0.022502,
     "end_time": "2022-02-20T14:52:47.090981",
     "exception": false,
     "start_time": "2022-02-20T14:52:47.068479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test = pd.read_csv(\"../input/ubiquant-market-prediction/example_test.csv\", usecols = test_data_types_dict.keys(),\n",
    "#                        dtype=test_data_types_dict)\n",
    "# test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05bd01f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:47.129669Z",
     "iopub.status.busy": "2022-02-20T14:52:47.128554Z",
     "iopub.status.idle": "2022-02-20T14:52:47.133265Z",
     "shell.execute_reply": "2022-02-20T14:52:47.132349Z",
     "shell.execute_reply.started": "2022-02-20T14:16:06.006082Z"
    },
    "papermill": {
     "duration": 0.027048,
     "end_time": "2022-02-20T14:52:47.133490",
     "exception": false,
     "start_time": "2022-02-20T14:52:47.106442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X=df.drop(['target'],axis=1)\n",
    "# y=df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30b1f19f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:47.172674Z",
     "iopub.status.busy": "2022-02-20T14:52:47.171592Z",
     "iopub.status.idle": "2022-02-20T14:52:47.175268Z",
     "shell.execute_reply": "2022-02-20T14:52:47.174447Z",
     "shell.execute_reply.started": "2022-02-20T14:16:06.016662Z"
    },
    "papermill": {
     "duration": 0.024112,
     "end_time": "2022-02-20T14:52:47.175489",
     "exception": false,
     "start_time": "2022-02-20T14:52:47.151377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install sparkmagic\n",
    "# !pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6de3565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:47.223846Z",
     "iopub.status.busy": "2022-02-20T14:52:47.222810Z",
     "iopub.status.idle": "2022-02-20T14:52:47.227720Z",
     "shell.execute_reply": "2022-02-20T14:52:47.226905Z",
     "shell.execute_reply.started": "2022-02-20T14:16:06.052740Z"
    },
    "papermill": {
     "duration": 0.028085,
     "end_time": "2022-02-20T14:52:47.227929",
     "exception": false,
     "start_time": "2022-02-20T14:52:47.199844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# shutil.copyfile(\"/root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f/pyspark-3.2.1-py2.py3-none-any.whl\", \"./pyspark-3.2.1-py2.py3-none-any.whl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa4368e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:47.271767Z",
     "iopub.status.busy": "2022-02-20T14:52:47.270789Z",
     "iopub.status.idle": "2022-02-20T14:52:47.274913Z",
     "shell.execute_reply": "2022-02-20T14:52:47.275462Z",
     "shell.execute_reply.started": "2022-02-20T14:16:06.058782Z"
    },
    "papermill": {
     "duration": 0.025358,
     "end_time": "2022-02-20T14:52:47.275656",
     "exception": false,
     "start_time": "2022-02-20T14:52:47.250298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.types import *\n",
    "# from pyspark.sql.functions import *\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# from pyspark.ml import Pipeline\n",
    "# #from pyspark.ml.classification import DecisionTreeClassifier\n",
    "# from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
    "# from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "\n",
    "# from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e85b3f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:47.313712Z",
     "iopub.status.busy": "2022-02-20T14:52:47.312905Z",
     "iopub.status.idle": "2022-02-20T14:52:47.315271Z",
     "shell.execute_reply": "2022-02-20T14:52:47.315717Z",
     "shell.execute_reply.started": "2022-02-20T14:16:06.070280Z"
    },
    "papermill": {
     "duration": 0.02363,
     "end_time": "2022-02-20T14:52:47.315891",
     "exception": false,
     "start_time": "2022-02-20T14:52:47.292261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# csv = spark.read.csv(\"../input/ubiquant-market-prediction/train.csv\",  header=True).createOrReplaceTempView(\"A\")\n",
    "# spark.read.csv(\"../input/ubiquant-market-prediction/train.csv\",  header=True).select(countDistinct(\"investment_id\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc8e59c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:47.350841Z",
     "iopub.status.busy": "2022-02-20T14:52:47.350215Z",
     "iopub.status.idle": "2022-02-20T14:52:47.353422Z",
     "shell.execute_reply": "2022-02-20T14:52:47.353903Z",
     "shell.execute_reply.started": "2022-02-20T14:16:06.080064Z"
    },
    "papermill": {
     "duration": 0.022168,
     "end_time": "2022-02-20T14:52:47.354103",
     "exception": false,
     "start_time": "2022-02-20T14:52:47.331935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pyspark.sql.functions as F\n",
    "# path=\"../input/ubiquant-market-prediction/train.csv\"\n",
    "# def getDistinctCountByColumn(path,column):\n",
    "#     return spark.read.csv(path,  header=True).select(countDistinct(column)).collect()\n",
    "\n",
    "# def getCount(path):\n",
    "#     return spark.read.csv(path,  header=True).select(count(\"*\")).collect()\n",
    "    \n",
    "# def extractData(offset,fetch,path,partCol):\n",
    "#     return spark.read.csv(path,  header=True,inferSchema=True).where(F.col(partCol).between(offset, offset+fetch))\n",
    "# # df=extractData(1,10,path,'investment_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59550cf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:47.387889Z",
     "iopub.status.busy": "2022-02-20T14:52:47.387222Z",
     "iopub.status.idle": "2022-02-20T14:52:47.389833Z",
     "shell.execute_reply": "2022-02-20T14:52:47.390306Z",
     "shell.execute_reply.started": "2022-02-20T14:16:06.090520Z"
    },
    "papermill": {
     "duration": 0.021211,
     "end_time": "2022-02-20T14:52:47.390487",
     "exception": false,
     "start_time": "2022-02-20T14:52:47.369276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# insIdCt=getDistinctCountByColumn(path,'investment_id')\n",
    "# insIdCt=getCount(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "223378ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:47.425371Z",
     "iopub.status.busy": "2022-02-20T14:52:47.424624Z",
     "iopub.status.idle": "2022-02-20T14:52:49.334861Z",
     "shell.execute_reply": "2022-02-20T14:52:49.334235Z",
     "shell.execute_reply.started": "2022-02-20T14:16:06.110761Z"
    },
    "papermill": {
     "duration": 1.928788,
     "end_time": "2022-02-20T14:52:49.335011",
     "exception": false,
     "start_time": "2022-02-20T14:52:47.406223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import lightgbm as lgb\n",
    "# !pip install optuna\n",
    "import optuna\n",
    "import os.path\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "class Objective():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.best_booster = None\n",
    "        self._booster = None\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        param = {\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"mean_squared_error\",\n",
    "            \"verbosity\": -1,\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"feature_fraction\": trial.suggest_loguniform(\"feature_fraction\", 0.5, 1.0),\n",
    "#             \"bagging_fraction\": trial.suggest_loguniform(\"bagging_fraction\", 0.5, 1.0),\n",
    "#             \"min_gain_to_split\": trial.suggest_loguniform(\"min_gain_to_split\", 0.3, 1.0),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 400, 550),\n",
    "            \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "            \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 900, 1200),\n",
    "#             \"num_iterations\": trial.suggest_int(\"num_iterations\", 20, 100),\n",
    "            \"learning_rate\":trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 20, 100),\n",
    "            \"max_bin\":trial.suggest_int(\"max_bin\", 500, 1000),\n",
    "        }\n",
    "        dtrain = lgb.Dataset(X, label=y)\n",
    "        # Add a callback for pruning.\n",
    "        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"mean_squared_error\")\n",
    "        if(os.path.isfile(\"./ubiquant-train-models/saved_models/lgbm/mdl.txt\")==True):\n",
    "            gbm=lgb.Booster(model_file=path1+\"mdl.txt\")\n",
    "            gbm = lgb.train(param, dtrain, valid_sets=[dtrain], verbose_eval=False,keep_training_booster =True,init_model=gbm)\n",
    "            gbm.save_model(path1+'mdl.txt')\n",
    "        if(os.path.isfile(\"./ubiquant-train-models/saved_models/lgbm/mdl.txt\")==False):\n",
    "            gbm = lgb.train(param, dtrain, valid_sets=[dtrain], verbose_eval=False,keep_training_booster =True)\n",
    "            gbm.save_model(path1+'mdl.txt')\n",
    "\n",
    "        self._booster = gbm\n",
    "\n",
    "        preds = gbm.predict(X)\n",
    "        pred_labels = np.rint(preds)\n",
    "        accuracy = mean_absolute_error(y, pred_labels)\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d37436b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:49.371682Z",
     "iopub.status.busy": "2022-02-20T14:52:49.370649Z",
     "iopub.status.idle": "2022-02-20T14:52:49.375970Z",
     "shell.execute_reply": "2022-02-20T14:52:49.376476Z",
     "shell.execute_reply.started": "2022-02-20T14:16:06.127224Z"
    },
    "papermill": {
     "duration": 0.025688,
     "end_time": "2022-02-20T14:52:49.376664",
     "exception": false,
     "start_time": "2022-02-20T14:52:49.350976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hyperTune(n_trials):\n",
    "    objective = Objective()\n",
    "    optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"minimize\"\n",
    "    )\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    trial_co = study.best_trial\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial_co.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "    return objective.best_booster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f379e756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T14:52:49.411610Z",
     "iopub.status.busy": "2022-02-20T14:52:49.410975Z",
     "iopub.status.idle": "2022-02-20T22:23:33.623478Z",
     "shell.execute_reply": "2022-02-20T22:23:33.625211Z"
    },
    "papermill": {
     "duration": 27044.235683,
     "end_time": "2022-02-20T22:23:33.628021",
     "exception": false,
     "start_time": "2022-02-20T14:52:49.392338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "*************************\n",
      "0 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "&&&&&&&&&&&&&&&&&&&&&&\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.145231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 250132\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.023366\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 250132\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "0 0.001240109427532343\n",
      "***************************\n",
      "*************************\n",
      "1 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 250324\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "1 0.011931626480726676\n",
      "***************************\n",
      "*************************\n",
      "2 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300023\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "2 0.011465620714556316\n",
      "***************************\n",
      "*************************\n",
      "3 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300025\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "3 0.012747414467709255\n",
      "***************************\n",
      "*************************\n",
      "4 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.130302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300024\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "4 0.013715216720554608\n",
      "***************************\n",
      "*************************\n",
      "5 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 299828\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "5 0.01498913286425812\n",
      "***************************\n",
      "*************************\n",
      "6 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 250244\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "6 0.015677573979865637\n",
      "***************************\n",
      "*************************\n",
      "7 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 250430\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "7 0.015541983648432955\n",
      "***************************\n",
      "*************************\n",
      "8 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 250029\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "8 0.016668064061156423\n",
      "***************************\n",
      "*************************\n",
      "9 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 250039\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "9 0.01484776411182261\n",
      "***************************\n",
      "*************************\n",
      "10 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 250888\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "10 0.01481416525921603\n",
      "***************************\n",
      "*************************\n",
      "11 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 249970\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "11 0.018361884716388388\n",
      "***************************\n",
      "*************************\n",
      "12 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 249862\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "12 0.018155974412394388\n",
      "***************************\n",
      "*************************\n",
      "13 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300012\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "13 0.01721348386136221\n",
      "***************************\n",
      "*************************\n",
      "14 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.136185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300025\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "14 0.015051802208130956\n",
      "***************************\n",
      "*************************\n",
      "15 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300027\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "15 0.01544452318448471\n",
      "***************************\n",
      "*************************\n",
      "16 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 299741\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "16 0.01983201836058186\n",
      "***************************\n",
      "*************************\n",
      "17 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.151828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 250914\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "17 0.021491523799957977\n",
      "***************************\n",
      "*************************\n",
      "18 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 249510\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "18 0.02393793151221335\n",
      "***************************\n",
      "*************************\n",
      "19 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 249786\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "19 0.025495825059011764\n",
      "***************************\n",
      "*************************\n",
      "20 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 249814\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "20 0.026707961932178188\n",
      "***************************\n",
      "*************************\n",
      "21 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 247333\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "21 0.02732508414851864\n",
      "***************************\n",
      "*************************\n",
      "22 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 247348\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "22 0.03079108720940308\n",
      "***************************\n",
      "*************************\n",
      "23 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 248914\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "23 0.03374931460381146\n",
      "***************************\n",
      "*************************\n",
      "24 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 249606\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "24 0.034299489459269555\n",
      "***************************\n",
      "*************************\n",
      "25 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300023\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "25 0.033465525706787416\n",
      "***************************\n",
      "*************************\n",
      "26 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.161478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300022\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "26 0.032401312583169764\n",
      "***************************\n",
      "*************************\n",
      "27 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.189328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300021\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "27 0.034980738931656166\n",
      "***************************\n",
      "*************************\n",
      "28 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300022\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "28 0.04108820768938574\n",
      "***************************\n",
      "*************************\n",
      "29 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300021\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "29 0.04105167510595792\n",
      "***************************\n",
      "*************************\n",
      "30 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300021\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "30 0.0376166207893712\n",
      "***************************\n",
      "*************************\n",
      "31 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300020\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "31 0.0407764737983761\n",
      "***************************\n",
      "*************************\n",
      "32 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300021\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "32 0.047693166339305364\n",
      "***************************\n",
      "*************************\n",
      "33 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 247656\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "33 0.0536955664573685\n",
      "***************************\n",
      "*************************\n",
      "34 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 247628\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "34 0.057084201312337726\n",
      "***************************\n",
      "*************************\n",
      "35 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 248129\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "35 0.0603103732764476\n",
      "***************************\n",
      "*************************\n",
      "36 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 248320\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "36 0.06182878300847143\n",
      "***************************\n",
      "*************************\n",
      "37 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300017\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "37 0.06627831178921322\n",
      "***************************\n",
      "*************************\n",
      "38 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300019\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "38 0.059771425477048445\n",
      "***************************\n",
      "*************************\n",
      "39 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300019\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "39 0.06630307989925319\n",
      "***************************\n",
      "*************************\n",
      "40 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300019\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "40 0.07189614091532477\n",
      "***************************\n",
      "*************************\n",
      "41 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300019\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "41 0.07789503590742378\n",
      "***************************\n",
      "*************************\n",
      "42 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300019\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "42 0.07721068884049136\n",
      "***************************\n",
      "*************************\n",
      "43 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "43 0.08113618336118793\n",
      "***************************\n",
      "*************************\n",
      "44 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 299198\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "44 0.09362631019551\n",
      "***************************\n",
      "*************************\n",
      "45 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 288537\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "45 0.10098653458497353\n",
      "***************************\n",
      "*************************\n",
      "46 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "46 0.09225851998271166\n",
      "***************************\n",
      "*************************\n",
      "47 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "47 0.09749670760025743\n",
      "***************************\n",
      "*************************\n",
      "48 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "48 0.10113479383272633\n",
      "***************************\n",
      "*************************\n",
      "49 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "49 0.11057437617916305\n",
      "***************************\n",
      "*************************\n",
      "50 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 245527\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "50 0.12876472832855684\n",
      "***************************\n",
      "*************************\n",
      "51 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.233215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "51 0.1343212492696241\n",
      "***************************\n",
      "*************************\n",
      "52 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.140905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300017\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "52 0.13064967276550338\n",
      "***************************\n",
      "*************************\n",
      "53 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.155077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "53 0.14116255114107068\n",
      "***************************\n",
      "*************************\n",
      "54 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "54 0.14877481572584492\n",
      "***************************\n",
      "*************************\n",
      "55 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.167534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "55 0.15057643668533957\n",
      "***************************\n",
      "*************************\n",
      "56 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300017\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "56 0.16235652889529512\n",
      "***************************\n",
      "*************************\n",
      "57 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.143827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300017\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "57 0.1771410165445653\n",
      "***************************\n",
      "*************************\n",
      "58 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300017\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "58 0.17921413619093413\n",
      "***************************\n",
      "*************************\n",
      "59 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "59 0.1830378243345105\n",
      "***************************\n",
      "*************************\n",
      "60 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300017\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "60 0.19474546446075092\n",
      "***************************\n",
      "*************************\n",
      "61 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 300016\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "61 0.20342277657369098\n",
      "***************************\n",
      "*************************\n",
      "62 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 96.05 MB\n",
      "Memory usage after optimization is: 24.25 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 299473\n",
      "[LightGBM] [Info] Number of data points in the train set: 41411, number of used features: 301\n",
      "***************************\n",
      "62 0.1328206111716219\n",
      "***************************\n",
      "*************************\n",
      "63 41411\n",
      "*************************\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.00 MB\n",
      "Decreased by nan%\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import gc\n",
    "gc.enable()\n",
    "Path(\"./ubiquant-train-models/saved_models/lgbm/\").mkdir(parents=True, exist_ok=True)\n",
    "path=\"../input/ubiquant-market-prediction/train.csv\"\n",
    "path1=\"./ubiquant-train-models/saved_models/lgbm/\"\n",
    "# model=lgb.LGBMRegressor(max_depth=100,num_leaves=600,num_iterations=100, keep_training_booster=True )\n",
    "sample_size=50000\n",
    "# loop=math.ceil(insIdCt[0][0]/sample_size)\n",
    "i=0\n",
    "df=df=reduce_mem_usage(pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows  = [j for j in range(1, i*sample_size) ],nrows=sample_size))\n",
    "lgb_path=\"./lg_model/\"\n",
    "while(len(df)>0):\n",
    "    print(\"*************************\")\n",
    "    print(i,len(df))\n",
    "    print(\"*************************\")\n",
    "#     df=extractData(i*sample_size,(i*sample_size)+sample_size,path,'investment_id').toPandas()\n",
    "    df=reduce_mem_usage(pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows  = [j for j in range(1, i*sample_size) ],nrows=sample_size))\n",
    "    df_1=pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows = 0,nrows=1)\n",
    "    df.columns=df_1.columns\n",
    "    del df_1\n",
    "    if(len(df)==0):\n",
    "        print(123)\n",
    "        break;\n",
    "    X=np.array(df.drop(['target','row_id','investment_id'],axis=1))\n",
    "    y=np.array(df['target'])\n",
    "    \n",
    "    params={\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "#         \"feature_fraction\": 0.75,\n",
    "#     \"bagging_fraction\": 0.75,\n",
    "#     \"min_gain_to_split\": 0.48621442782475605,\n",
    "    \"max_depth\": 500,\n",
    "#     \"lambda_l1\": 0.03742217988743394,\n",
    "#     \"lambda_l2\": 0.20030511153917615294,\n",
    "    \"num_leaves\": 1000,\n",
    "    \"num_iterations\": 100,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_bin\": 1000}\n",
    "    dtrain = lgb.Dataset(X, label=y, free_raw_data=False)\n",
    "#     params =  hyperTune(25)\n",
    "#     gbm=lgb.Booster(model_file=path1+\"mdl.txt\")\n",
    "    model= lgb.LGBMRegressor(params)\n",
    "    if(i==0):\n",
    "        print(\"&&&&&&&&&&&&&&&&&&&&&&\")\n",
    "        gbm = lgb.train(params, dtrain, valid_sets=[dtrain], verbose_eval=False,keep_training_booster =True)\n",
    "        gbm.save_model(path1+'mdl.txt')\n",
    "    gbm=lgb.Booster(model_file=path1+\"mdl.txt\")\n",
    "    gbm = lgb.train(params, dtrain, valid_sets=[dtrain], verbose_eval=False,keep_training_booster =True,init_model=gbm)\n",
    "    gbm.save_model(path1+'mdl.txt')\n",
    "#     gbm = model.fit(X,y)\n",
    "    y_pred=gbm.predict(X)\n",
    "    MSE(y, y_pred)\n",
    "    print(\"***************************\")\n",
    "    print(i,MSE(pd.DataFrame(y), pd.DataFrame(y_pred)))\n",
    "    print(\"***************************\")\n",
    "    del X\n",
    "    del y\n",
    "    del dtrain\n",
    "    i+=1\n",
    "    gc.collect()\n",
    "# del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "362a0c9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T22:23:33.823901Z",
     "iopub.status.busy": "2022-02-20T22:23:33.821730Z",
     "iopub.status.idle": "2022-02-20T22:23:38.360917Z",
     "shell.execute_reply": "2022-02-20T22:23:38.360310Z"
    },
    "papermill": {
     "duration": 4.642019,
     "end_time": "2022-02-20T22:23:38.361098",
     "exception": false,
     "start_time": "2022-02-20T22:23:33.719079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "import ubiquant\n",
    "env = ubiquant.make_env()\n",
    "iter_test = env.iter_test() \n",
    "model=lgb.Booster(model_file=path1+\"mdl.txt\") \n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    sample_prediction_df['target'] = model.predict(test_df.drop(['row_id'],axis=1))\n",
    "#     sample_prediction_df\n",
    "    env.predict(sample_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9597047a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T22:23:38.555897Z",
     "iopub.status.busy": "2022-02-20T22:23:38.555165Z",
     "iopub.status.idle": "2022-02-20T22:23:38.557216Z",
     "shell.execute_reply": "2022-02-20T22:23:38.557896Z"
    },
    "papermill": {
     "duration": 0.097901,
     "end_time": "2022-02-20T22:23:38.558094",
     "exception": false,
     "start_time": "2022-02-20T22:23:38.460193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# insIdCt=getCount(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ce9c5c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T22:23:38.746990Z",
     "iopub.status.busy": "2022-02-20T22:23:38.744532Z",
     "iopub.status.idle": "2022-02-20T22:23:38.749540Z",
     "shell.execute_reply": "2022-02-20T22:23:38.749036Z"
    },
    "papermill": {
     "duration": 0.100128,
     "end_time": "2022-02-20T22:23:38.749671",
     "exception": false,
     "start_time": "2022-02-20T22:23:38.649543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import math\n",
    "# import lightgbm as lgb\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# def generator(size1):\n",
    "#     loop=math.ceil(insIdCt[0][0]/size1)\n",
    "#     i=0\n",
    "#     while(i<=loop):\n",
    "#         df=pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows = [j for j in range(1, i*size1) ],nrows=size1)\n",
    "#         df_1=pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\",nrows=1)\n",
    "#         df.columns=df_1.columns\n",
    "#         X=np.array(df.drop(['target','row_id'],axis=1))\n",
    "#         y=np.array(df['target'])\n",
    "#         i+=1\n",
    "#         del df\n",
    "#         yield X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9606031d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T22:23:38.939305Z",
     "iopub.status.busy": "2022-02-20T22:23:38.938367Z",
     "iopub.status.idle": "2022-02-20T22:23:38.940942Z",
     "shell.execute_reply": "2022-02-20T22:23:38.940513Z"
    },
    "papermill": {
     "duration": 0.09722,
     "end_time": "2022-02-20T22:23:38.941087",
     "exception": false,
     "start_time": "2022-02-20T22:23:38.843867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # import the necessary modules from the library\n",
    "# size1=1024\n",
    "# train_generator =generator(size1)\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Conv2D, Flatten, Activation, LSTM, Dropout,BatchNormalization,RepeatVector\n",
    "# model = Sequential()\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(1024))\n",
    "# model.add(Activation('swish'))\n",
    "# model.add(RepeatVector(3))\n",
    "# model.add(LSTM(512, activation = 'swish', return_sequences=True))\n",
    "# # model.add(Dropout(0.3))\n",
    "# model.add(LSTM(256, activation = 'swish', return_sequences=True))\n",
    "# # model.add(Dropout(0.3))\n",
    "# model.add(Dense(1))\n",
    "# model.add(Activation('softmax'))\n",
    "# model.compile(loss='MeanSquaredError',\n",
    "#               optimizer='adam',#'rmsprop',\n",
    "#               metrics=['mean_squared_error'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bf3f050",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T22:23:39.126153Z",
     "iopub.status.busy": "2022-02-20T22:23:39.125558Z",
     "iopub.status.idle": "2022-02-20T22:23:39.127162Z",
     "shell.execute_reply": "2022-02-20T22:23:39.127547Z"
    },
    "papermill": {
     "duration": 0.096148,
     "end_time": "2022-02-20T22:23:39.127700",
     "exception": false,
     "start_time": "2022-02-20T22:23:39.031552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.fit_generator(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=size1, #// batch_size,\n",
    "#         epochs=10\n",
    "# #         validation_data=train_generator,\n",
    "# #         validation_steps=64\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7648fb2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T22:23:39.311645Z",
     "iopub.status.busy": "2022-02-20T22:23:39.311118Z",
     "iopub.status.idle": "2022-02-20T22:23:39.313818Z",
     "shell.execute_reply": "2022-02-20T22:23:39.314255Z"
    },
    "papermill": {
     "duration": 0.095974,
     "end_time": "2022-02-20T22:23:39.314421",
     "exception": false,
     "start_time": "2022-02-20T22:23:39.218447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a=extractData(i*5,(i*5)+5,path,'investment_id')\n",
    "# [j for j in range(1, i*size1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4a338ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T22:23:39.498787Z",
     "iopub.status.busy": "2022-02-20T22:23:39.498219Z",
     "iopub.status.idle": "2022-02-20T22:23:39.501511Z",
     "shell.execute_reply": "2022-02-20T22:23:39.501069Z"
    },
    "papermill": {
     "duration": 0.096553,
     "end_time": "2022-02-20T22:23:39.501638",
     "exception": false,
     "start_time": "2022-02-20T22:23:39.405085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # b=a.toPandas()[100]\n",
    "# a.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f17d2c",
   "metadata": {
    "papermill": {
     "duration": 0.090989,
     "end_time": "2022-02-20T22:23:39.683220",
     "exception": false,
     "start_time": "2022-02-20T22:23:39.592231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27065.012676,
   "end_time": "2022-02-20T22:23:41.801523",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-20T14:52:36.788847",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
