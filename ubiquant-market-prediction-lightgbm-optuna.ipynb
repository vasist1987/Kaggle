{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9176b511",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-21T18:06:06.098730Z",
     "iopub.status.busy": "2022-02-21T18:06:06.096883Z",
     "iopub.status.idle": "2022-02-21T18:06:07.219032Z",
     "shell.execute_reply": "2022-02-21T18:06:07.219927Z",
     "shell.execute_reply.started": "2022-02-21T17:32:13.964826Z"
    },
    "papermill": {
     "duration": 1.144576,
     "end_time": "2022-02-21T18:06:07.220334",
     "exception": false,
     "start_time": "2022-02-21T18:06:06.075758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ubiquant-market-prediction/example_sample_submission.csv\n",
      "/kaggle/input/ubiquant-market-prediction/example_test.csv\n",
      "/kaggle/input/ubiquant-market-prediction/train.csv\n",
      "/kaggle/input/ubiquant-market-prediction/ubiquant/competition.cpython-37m-x86_64-linux-gnu.so\n",
      "/kaggle/input/ubiquant-market-prediction/ubiquant/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7f8bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T18:06:07.268506Z",
     "iopub.status.busy": "2022-02-21T18:06:07.267770Z",
     "iopub.status.idle": "2022-02-21T18:06:07.269860Z",
     "shell.execute_reply": "2022-02-21T18:06:07.270439Z",
     "shell.execute_reply.started": "2022-02-21T17:32:14.082698Z"
    },
    "papermill": {
     "duration": 0.033216,
     "end_time": "2022-02-21T18:06:07.270627",
     "exception": false,
     "start_time": "2022-02-21T18:06:07.237411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype.name\n",
    "\n",
    "        if col_type not in ['object', 'category', 'datetime64[ns, UTC]']:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c36b15af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T18:06:07.303522Z",
     "iopub.status.busy": "2022-02-21T18:06:07.302683Z",
     "iopub.status.idle": "2022-02-21T18:06:07.307312Z",
     "shell.execute_reply": "2022-02-21T18:06:07.306719Z",
     "shell.execute_reply.started": "2022-02-21T17:32:14.096572Z"
    },
    "papermill": {
     "duration": 0.022317,
     "end_time": "2022-02-21T18:06:07.307463",
     "exception": false,
     "start_time": "2022-02-21T18:06:07.285146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# insIdCt=getDistinctCountByColumn(path,'investment_id')\n",
    "# insIdCt=getCount(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2108d734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T18:06:07.339936Z",
     "iopub.status.busy": "2022-02-21T18:06:07.339167Z",
     "iopub.status.idle": "2022-02-21T18:06:09.377377Z",
     "shell.execute_reply": "2022-02-21T18:06:09.377972Z",
     "shell.execute_reply.started": "2022-02-21T17:32:14.108477Z"
    },
    "papermill": {
     "duration": 2.056107,
     "end_time": "2022-02-21T18:06:09.378148",
     "exception": false,
     "start_time": "2022-02-21T18:06:07.322041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import lightgbm as lgb\n",
    "# !pip install optuna\n",
    "import optuna\n",
    "import os.path\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "class Objective():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.best_booster = None\n",
    "        self._booster = None\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        param = {\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"mean_squared_error\",\n",
    "            \"verbosity\": -1,\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"feature_fraction\": trial.suggest_loguniform(\"feature_fraction\", 0.5, 1.0),\n",
    "            \"bagging_fraction\": trial.suggest_loguniform(\"bagging_fraction\", 0.3, 1.0),\n",
    "#             \"min_gain_to_split\": trial.suggest_loguniform(\"min_gain_to_split\", 0.3, 1.0),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 400, 550),\n",
    "#             \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "#             \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 900, 1200),\n",
    "#             \"num_iterations\": trial.suggest_int(\"num_iterations\", 20, 100),\n",
    "            \"learning_rate\":trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 25),\n",
    "            \"max_bin\":trial.suggest_int(\"max_bin\", 500, 1000),\n",
    "        }\n",
    "        dtrain = lgb.Dataset(X, label=y)\n",
    "        # Add a callback for pruning.\n",
    "        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"mean_squared_error\")\n",
    "        if(os.path.isfile(\"./ubiquant-train-models/saved_models/lgbm/mdl.txt\")==True):\n",
    "            gbm=lgb.Booster(model_file=path1+\"mdl.txt\")\n",
    "            gbm = lgb.train(param, dtrain, valid_sets=[dtrain], verbose_eval=False,keep_training_booster =True,init_model=gbm)\n",
    "            gbm.save_model(path1+'mdl.txt')\n",
    "        if(os.path.isfile(\"./ubiquant-train-models/saved_models/lgbm/mdl.txt\")==False):\n",
    "            gbm = lgb.train(param, dtrain, valid_sets=[dtrain], verbose_eval=False,keep_training_booster =True)\n",
    "            gbm.save_model(path1+'mdl.txt')\n",
    "\n",
    "        self._booster = gbm\n",
    "\n",
    "        preds = gbm.predict(X)\n",
    "        pred_labels = np.rint(preds)\n",
    "        accuracy = mean_absolute_error(y, pred_labels)\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e27296d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T18:06:09.412004Z",
     "iopub.status.busy": "2022-02-21T18:06:09.411352Z",
     "iopub.status.idle": "2022-02-21T18:06:09.417452Z",
     "shell.execute_reply": "2022-02-21T18:06:09.417967Z",
     "shell.execute_reply.started": "2022-02-21T17:32:14.775050Z"
    },
    "papermill": {
     "duration": 0.02462,
     "end_time": "2022-02-21T18:06:09.418138",
     "exception": false,
     "start_time": "2022-02-21T18:06:09.393518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hyperTune(n_trials):\n",
    "    objective = Objective()\n",
    "    optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"minimize\"\n",
    "    )\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    trial_co = study.best_trial\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial_co.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "    return objective.best_booster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b285a291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T18:06:09.451864Z",
     "iopub.status.busy": "2022-02-21T18:06:09.451122Z",
     "iopub.status.idle": "2022-02-21T20:26:42.513661Z",
     "shell.execute_reply": "2022-02-21T20:26:42.514753Z"
    },
    "papermill": {
     "duration": 8433.084725,
     "end_time": "2022-02-21T20:26:42.517877",
     "exception": false,
     "start_time": "2022-02-21T18:06:09.433152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "*************************\n",
      "0 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "&&&&&&&&&&&&&&&&&&&&&&\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.137391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129415\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.023366\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.135548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129415\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "0 0.09763994784252958\n",
      "***************************\n",
      "*************************\n",
      "1 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.140019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129425\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "1 0.2664776400251214\n",
      "***************************\n",
      "*************************\n",
      "2 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150023\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "2 0.27848709492376134\n",
      "***************************\n",
      "*************************\n",
      "3 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150025\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "3 0.3130120956511076\n",
      "***************************\n",
      "*************************\n",
      "4 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150024\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "4 0.3232467149664422\n",
      "***************************\n",
      "*************************\n",
      "5 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150023\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "5 0.31811916184956884\n",
      "***************************\n",
      "*************************\n",
      "6 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129550\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "6 0.329725404393937\n",
      "***************************\n",
      "*************************\n",
      "7 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.139466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129420\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "7 0.3331835115342021\n",
      "***************************\n",
      "*************************\n",
      "8 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129197\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "8 0.36266131970344706\n",
      "***************************\n",
      "*************************\n",
      "9 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129088\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "9 0.3539616580705574\n",
      "***************************\n",
      "*************************\n",
      "10 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129379\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "10 0.3241277908846215\n",
      "***************************\n",
      "*************************\n",
      "11 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129304\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "11 0.38054904489168584\n",
      "***************************\n",
      "*************************\n",
      "12 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129242\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "12 0.39459226300710004\n",
      "***************************\n",
      "*************************\n",
      "13 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150025\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "13 0.3940179827818468\n",
      "***************************\n",
      "*************************\n",
      "14 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150025\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "14 0.4113107003583712\n",
      "***************************\n",
      "*************************\n",
      "15 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150027\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "15 0.41832559742649084\n",
      "***************************\n",
      "*************************\n",
      "16 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149995\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "16 0.41956717110915925\n",
      "***************************\n",
      "*************************\n",
      "17 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129515\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "17 0.44370243586951963\n",
      "***************************\n",
      "*************************\n",
      "18 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.133836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129170\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "18 0.4632795237363524\n",
      "***************************\n",
      "*************************\n",
      "19 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129089\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "19 0.4768378807097252\n",
      "***************************\n",
      "*************************\n",
      "20 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128903\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "20 0.5147602903710651\n",
      "***************************\n",
      "*************************\n",
      "21 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128312\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "21 0.5209705603200204\n",
      "***************************\n",
      "*************************\n",
      "22 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128155\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "22 0.5537867860246907\n",
      "***************************\n",
      "*************************\n",
      "23 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128953\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "23 0.5960152002249672\n",
      "***************************\n",
      "*************************\n",
      "24 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.258521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129037\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "24 0.607868289288966\n",
      "***************************\n",
      "*************************\n",
      "25 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150023\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "25 0.6668118462401635\n",
      "***************************\n",
      "*************************\n",
      "26 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150022\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "26 0.7093850574245634\n",
      "***************************\n",
      "*************************\n",
      "27 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.187527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150021\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "27 0.7388558354867713\n",
      "***************************\n",
      "*************************\n",
      "28 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150022\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "28 0.7385211617609607\n",
      "***************************\n",
      "*************************\n",
      "29 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150021\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "29 0.7581847612885837\n",
      "***************************\n",
      "*************************\n",
      "30 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150021\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "30 0.792049351323037\n",
      "***************************\n",
      "*************************\n",
      "31 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150020\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "31 0.8136709539794054\n",
      "***************************\n",
      "*************************\n",
      "32 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150021\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "32 0.8403447861266125\n",
      "***************************\n",
      "*************************\n",
      "33 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.128960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128238\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "33 0.8054626245178076\n",
      "***************************\n",
      "*************************\n",
      "34 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128233\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "34 0.8206960844267696\n",
      "***************************\n",
      "*************************\n",
      "35 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128299\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "35 0.8681232005188932\n",
      "***************************\n",
      "*************************\n",
      "36 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128425\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "36 0.8758175322698667\n",
      "***************************\n",
      "*************************\n",
      "37 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150020\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "37 0.9806784860310814\n",
      "***************************\n",
      "*************************\n",
      "38 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150019\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "38 1.107151891540936\n",
      "***************************\n",
      "*************************\n",
      "39 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150019\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "39 1.1696565722804222\n",
      "***************************\n",
      "*************************\n",
      "40 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150019\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "40 1.2804571856786846\n",
      "***************************\n",
      "*************************\n",
      "41 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150019\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "41 1.2991695161418049\n",
      "***************************\n",
      "*************************\n",
      "42 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150019\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "42 1.2690444712722933\n",
      "***************************\n",
      "*************************\n",
      "43 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "43 1.2783911034595283\n",
      "***************************\n",
      "*************************\n",
      "44 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149839\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "44 1.2209691777420926\n",
      "***************************\n",
      "*************************\n",
      "45 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149325\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "45 1.2388478635816673\n",
      "***************************\n",
      "*************************\n",
      "46 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "46 1.4858769155884914\n",
      "***************************\n",
      "*************************\n",
      "47 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "47 1.5326901813016085\n",
      "***************************\n",
      "*************************\n",
      "48 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "48 1.5788105658357041\n",
      "***************************\n",
      "*************************\n",
      "49 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "49 1.661373908807129\n",
      "***************************\n",
      "*************************\n",
      "50 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 127382\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 300\n",
      "***************************\n",
      "50 1.5287885257339822\n",
      "***************************\n",
      "*************************\n",
      "51 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "51 1.7623599147730993\n",
      "***************************\n",
      "*************************\n",
      "52 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150017\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "52 1.876857190905946\n",
      "***************************\n",
      "*************************\n",
      "53 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "53 2.006648776541161\n",
      "***************************\n",
      "*************************\n",
      "54 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "54 2.1392650944087137\n",
      "***************************\n",
      "*************************\n",
      "55 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "55 2.124206168759481\n",
      "***************************\n",
      "*************************\n",
      "56 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150017\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "56 2.182284912657272\n",
      "***************************\n",
      "*************************\n",
      "57 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150017\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "57 2.1768433543034686\n",
      "***************************\n",
      "*************************\n",
      "58 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150017\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "58 2.3389021519224196\n",
      "***************************\n",
      "*************************\n",
      "59 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150018\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "59 2.417907179925661\n",
      "***************************\n",
      "*************************\n",
      "60 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150017\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "60 2.521305107841136\n",
      "***************************\n",
      "*************************\n",
      "61 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 115.97 MB\n",
      "Memory usage after optimization is: 29.28 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150016\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 301\n",
      "***************************\n",
      "61 2.6192167986337687\n",
      "***************************\n",
      "*************************\n",
      "62 50000\n",
      "*************************\n",
      "Memory usage of dataframe is 96.05 MB\n",
      "Memory usage after optimization is: 24.25 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149817\n",
      "[LightGBM] [Info] Number of data points in the train set: 41411, number of used features: 301\n",
      "***************************\n",
      "62 2.217521141911948\n",
      "***************************\n",
      "*************************\n",
      "63 41411\n",
      "*************************\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.00 MB\n",
      "Decreased by nan%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import gc\n",
    "gc.enable()\n",
    "Path(\"./ubiquant-train-models/saved_models/lgbm/\").mkdir(parents=True, exist_ok=True)\n",
    "path=\"../input/ubiquant-market-prediction/train.csv\"\n",
    "path1=\"./ubiquant-train-models/saved_models/lgbm/\"\n",
    "# model=lgb.LGBMRegressor(max_depth=100,num_leaves=600,num_iterations=100, keep_training_booster=True )\n",
    "sample_size=50000\n",
    "# loop=math.ceil(insIdCt[0][0]/sample_size)\n",
    "i=0\n",
    "df=df=reduce_mem_usage(pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows  = [j for j in range(1, i*sample_size) ],nrows=sample_size))\n",
    "lgb_path=\"./lg_model/\"\n",
    "while(len(df)>0):\n",
    "    print(\"*************************\")\n",
    "    print(i,len(df))\n",
    "    print(\"*************************\")\n",
    "#     df=extractData(i*sample_size,(i*sample_size)+sample_size,path,'investment_id').toPandas()\n",
    "    df=reduce_mem_usage(pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows  = [j for j in range(1, i*sample_size) ],nrows=sample_size))\n",
    "    df_1=pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows = 0,nrows=1)\n",
    "    df.columns=df_1.columns\n",
    "    del df_1\n",
    "    if(len(df)==0):\n",
    "        break;\n",
    "    X=np.array(df.drop(['target','row_id','investment_id'],axis=1))\n",
    "    y=np.array(df['target'])\n",
    "    \n",
    "    params={\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"feature_fraction\": 0.7,\n",
    "    \"bagging_fraction\": 0.30,\n",
    "#     \"min_gain_to_split\": 0.48621442782475605,\n",
    "    \"max_depth\": 700,\n",
    "#     \"lambda_l1\": 0.03742217988743394,\n",
    "#     \"lambda_l2\": 0.20030511153917615294,\n",
    "    \"num_leaves\": 1400,\n",
    "    \"num_iterations\": 20,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 50,\n",
    "    \"max_bin\": 500}\n",
    "    dtrain = lgb.Dataset(X, label=y, free_raw_data=False)\n",
    "#     params =  hyperTune(25)\n",
    "#     gbm=lgb.Booster(model_file=path1+\"mdl.txt\")\n",
    "    gbm= lgb.LGBMRegressor(params)\n",
    "    if(i==0):\n",
    "        print(\"&&&&&&&&&&&&&&&&&&&&&&\")\n",
    "        gbm = lgb.train(params, dtrain, valid_sets=[dtrain], verbose_eval=False,keep_training_booster =True)\n",
    "        gbm.save_model(path1+'mdl.txt')\n",
    "    gbm=lgb.Booster(model_file=path1+\"mdl.txt\")\n",
    "    gbm = lgb.train(params, dtrain, valid_sets=[dtrain], verbose_eval=False,keep_training_booster =True,init_model=gbm)\n",
    "    gbm.save_model(path1+'mdl.txt')\n",
    "#     gbm = model.fit(X,y)\n",
    "    y_pred=gbm.predict(X)\n",
    "    MSE(y, y_pred)\n",
    "    print(\"***************************\")\n",
    "    print(i,MSE(pd.DataFrame(y), pd.DataFrame(y_pred)))\n",
    "    print(\"***************************\")\n",
    "    del X\n",
    "    del y\n",
    "    del dtrain\n",
    "    i+=1\n",
    "    gc.collect()\n",
    "# del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b89784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:26:42.766794Z",
     "iopub.status.busy": "2022-02-21T20:26:42.765997Z",
     "iopub.status.idle": "2022-02-21T20:26:44.639445Z",
     "shell.execute_reply": "2022-02-21T20:26:44.638813Z",
     "shell.execute_reply.started": "2022-02-21T17:32:50.550900Z"
    },
    "papermill": {
     "duration": 2.003854,
     "end_time": "2022-02-21T20:26:44.639615",
     "exception": false,
     "start_time": "2022-02-21T20:26:42.635761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "import ubiquant\n",
    "env = ubiquant.make_env()\n",
    "iter_test = env.iter_test() \n",
    "model=lgb.Booster(model_file=path1+\"mdl.txt\") \n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    sample_prediction_df['target'] = model.predict(test_df.drop(['row_id'],axis=1))\n",
    "#     sample_prediction_df\n",
    "    env.predict(sample_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db52eb0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:26:44.862718Z",
     "iopub.status.busy": "2022-02-21T20:26:44.861694Z",
     "iopub.status.idle": "2022-02-21T20:26:44.864485Z",
     "shell.execute_reply": "2022-02-21T20:26:44.863936Z",
     "shell.execute_reply.started": "2022-02-21T17:32:50.552828Z"
    },
    "papermill": {
     "duration": 0.11446,
     "end_time": "2022-02-21T20:26:44.864638",
     "exception": false,
     "start_time": "2022-02-21T20:26:44.750178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# insIdCt=getCount(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01cc1797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:26:45.085851Z",
     "iopub.status.busy": "2022-02-21T20:26:45.084834Z",
     "iopub.status.idle": "2022-02-21T20:26:45.087938Z",
     "shell.execute_reply": "2022-02-21T20:26:45.087366Z",
     "shell.execute_reply.started": "2022-02-21T17:32:50.554384Z"
    },
    "papermill": {
     "duration": 0.117179,
     "end_time": "2022-02-21T20:26:45.088092",
     "exception": false,
     "start_time": "2022-02-21T20:26:44.970913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import math\n",
    "# import lightgbm as lgb\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# def generator(size1):\n",
    "# #     loop=math.ceil(insIdCt[0][0]/size1)\n",
    "#     i=0\n",
    "#     df=reduce_mem_usage(pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows = [j for j in range(1, i*size1) ],nrows=size1))\n",
    "#     while(i>=0):\n",
    "        \n",
    "#         df=reduce_mem_usage(pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows = [j for j in range(1, i*size1) ],nrows=size1))\n",
    "#         if(len(df)==0):\n",
    "#             i=-1\n",
    "#         df_1=pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\",nrows=1)\n",
    "#         df.columns=df_1.columns\n",
    "#         X=np.array(df.drop(['target','row_id'],axis=1))\n",
    "#         y=np.array(df['target'])\n",
    "#         i+=1\n",
    "# #         del df\n",
    "#         yield X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1876ad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:26:45.310488Z",
     "iopub.status.busy": "2022-02-21T20:26:45.309498Z",
     "iopub.status.idle": "2022-02-21T20:26:45.311933Z",
     "shell.execute_reply": "2022-02-21T20:26:45.312419Z",
     "shell.execute_reply.started": "2022-02-21T17:32:50.556810Z"
    },
    "papermill": {
     "duration": 0.116828,
     "end_time": "2022-02-21T20:26:45.312603",
     "exception": false,
     "start_time": "2022-02-21T20:26:45.195775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i=0\n",
    "# size1=20000\n",
    "# df=reduce_mem_usage(pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows = [j for j in range(1, i*size1) ],nrows=size1))\n",
    "# while(i>=0):\n",
    "#     df=reduce_mem_usage(pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows = [j for j in range(1, i*size1) ],nrows=size1))\n",
    "#     print(len(df),i)\n",
    "#     if(len(df)==0):\n",
    "#         i=-1\n",
    "#     df_1=pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\",nrows=1)\n",
    "#     df.columns=df_1.columns\n",
    "#     X=np.array(df.drop(['target','row_id'],axis=1))\n",
    "#     y=np.array(df['target'])\n",
    "#     i+=1\n",
    "# #         del df\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "723b71c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:26:45.532157Z",
     "iopub.status.busy": "2022-02-21T20:26:45.531292Z",
     "iopub.status.idle": "2022-02-21T20:26:45.534658Z",
     "shell.execute_reply": "2022-02-21T20:26:45.534101Z",
     "shell.execute_reply.started": "2022-02-21T17:32:50.558676Z"
    },
    "papermill": {
     "duration": 0.11467,
     "end_time": "2022-02-21T20:26:45.534815",
     "exception": false,
     "start_time": "2022-02-21T20:26:45.420145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# size1=64\n",
    "# train_generator =generator(size1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eefcb20d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:26:45.758710Z",
     "iopub.status.busy": "2022-02-21T20:26:45.757609Z",
     "iopub.status.idle": "2022-02-21T20:26:45.760248Z",
     "shell.execute_reply": "2022-02-21T20:26:45.759705Z",
     "shell.execute_reply.started": "2022-02-21T17:32:50.560767Z"
    },
    "papermill": {
     "duration": 0.119324,
     "end_time": "2022-02-21T20:26:45.760412",
     "exception": false,
     "start_time": "2022-02-21T20:26:45.641088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # import the necessary modules from the library\n",
    "# size1=128\n",
    "# train_generator =generator(size1)\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Conv2D, Flatten, Activation, LSTM, Dropout,BatchNormalization,RepeatVector\n",
    "# model = Sequential()\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(1024))\n",
    "# model.add(Dense(1024))\n",
    "# model.add(Dense(1024))\n",
    "# model.add(Activation('swish'))\n",
    "# model.add(RepeatVector(3))\n",
    "# model.add(LSTM(512, activation = 'swish', return_sequences=True))\n",
    "# # model.add(Dropout(0.3))\n",
    "# model.add(LSTM(256, activation = 'swish', return_sequences=True))\n",
    "# # model.add(Dropout(0.3))\n",
    "# model.add(Dense(1))\n",
    "# model.add(Activation('softmax'))\n",
    "# model.compile(loss='MeanSquaredError',\n",
    "#               optimizer='adam',#'rmsprop',\n",
    "#               metrics=['mean_squared_error'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb0280fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:26:45.984090Z",
     "iopub.status.busy": "2022-02-21T20:26:45.983069Z",
     "iopub.status.idle": "2022-02-21T20:26:45.985481Z",
     "shell.execute_reply": "2022-02-21T20:26:45.986092Z",
     "shell.execute_reply.started": "2022-02-21T17:32:50.562584Z"
    },
    "papermill": {
     "duration": 0.117185,
     "end_time": "2022-02-21T20:26:45.986283",
     "exception": false,
     "start_time": "2022-02-21T20:26:45.869098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.fit_generator(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=size1, #// batch_size,\n",
    "#         epochs=1\n",
    "# #         validation_data=train_generator#,\n",
    "# #         validation_steps=64\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83184523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:26:46.212284Z",
     "iopub.status.busy": "2022-02-21T20:26:46.211197Z",
     "iopub.status.idle": "2022-02-21T20:26:46.215400Z",
     "shell.execute_reply": "2022-02-21T20:26:46.215960Z",
     "shell.execute_reply.started": "2022-02-21T17:32:50.564389Z"
    },
    "papermill": {
     "duration": 0.119365,
     "end_time": "2022-02-21T20:26:46.216141",
     "exception": false,
     "start_time": "2022-02-21T20:26:46.096776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a=extractData(i*5,(i*5)+5,path,'investment_id')\n",
    "# [j for j in range(1, i*size1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41dcecbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:26:46.439232Z",
     "iopub.status.busy": "2022-02-21T20:26:46.438214Z",
     "iopub.status.idle": "2022-02-21T20:26:46.441854Z",
     "shell.execute_reply": "2022-02-21T20:26:46.442451Z",
     "shell.execute_reply.started": "2022-02-21T17:32:50.565715Z"
    },
    "papermill": {
     "duration": 0.117738,
     "end_time": "2022-02-21T20:26:46.442631",
     "exception": false,
     "start_time": "2022-02-21T20:26:46.324893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # b=a.toPandas()[100]\n",
    "# a.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1947f2",
   "metadata": {
    "papermill": {
     "duration": 0.108293,
     "end_time": "2022-02-21T20:26:46.658352",
     "exception": false,
     "start_time": "2022-02-21T20:26:46.550059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8454.008224,
   "end_time": "2022-02-21T20:26:48.543890",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-21T18:05:54.535666",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
