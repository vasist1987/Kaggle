{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25030eb5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-22T10:16:02.768720Z",
     "iopub.status.busy": "2022-02-22T10:16:02.767816Z",
     "iopub.status.idle": "2022-02-22T10:16:03.873805Z",
     "shell.execute_reply": "2022-02-22T10:16:03.874333Z",
     "shell.execute_reply.started": "2022-02-22T08:47:27.609731Z"
    },
    "papermill": {
     "duration": 1.139381,
     "end_time": "2022-02-22T10:16:03.874638",
     "exception": false,
     "start_time": "2022-02-22T10:16:02.735257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ubiquant-market-prediction/example_sample_submission.csv\n",
      "/kaggle/input/ubiquant-market-prediction/example_test.csv\n",
      "/kaggle/input/ubiquant-market-prediction/train.csv\n",
      "/kaggle/input/ubiquant-market-prediction/ubiquant/competition.cpython-37m-x86_64-linux-gnu.so\n",
      "/kaggle/input/ubiquant-market-prediction/ubiquant/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a578923",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T10:16:03.923115Z",
     "iopub.status.busy": "2022-02-22T10:16:03.917898Z",
     "iopub.status.idle": "2022-02-22T10:16:03.929475Z",
     "shell.execute_reply": "2022-02-22T10:16:03.928854Z",
     "shell.execute_reply.started": "2022-02-22T08:47:28.550091Z"
    },
    "papermill": {
     "duration": 0.037182,
     "end_time": "2022-02-22T10:16:03.929641",
     "exception": false,
     "start_time": "2022-02-22T10:16:03.892459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype.name\n",
    "\n",
    "        if col_type not in ['object', 'category', 'datetime64[ns, UTC]']:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7d61bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T10:16:03.963530Z",
     "iopub.status.busy": "2022-02-22T10:16:03.962537Z",
     "iopub.status.idle": "2022-02-22T10:16:03.965794Z",
     "shell.execute_reply": "2022-02-22T10:16:03.966351Z",
     "shell.execute_reply.started": "2022-02-22T08:47:28.567534Z"
    },
    "papermill": {
     "duration": 0.021496,
     "end_time": "2022-02-22T10:16:03.966523",
     "exception": false,
     "start_time": "2022-02-22T10:16:03.945027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# insIdCt=getDistinctCountByColumn(path,'investment_id')\n",
    "# insIdCt=getCount(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2fe7c04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T10:16:04.000320Z",
     "iopub.status.busy": "2022-02-22T10:16:03.999257Z",
     "iopub.status.idle": "2022-02-22T10:16:06.068893Z",
     "shell.execute_reply": "2022-02-22T10:16:06.068211Z",
     "shell.execute_reply.started": "2022-02-22T08:47:28.582189Z"
    },
    "papermill": {
     "duration": 2.087311,
     "end_time": "2022-02-22T10:16:06.069041",
     "exception": false,
     "start_time": "2022-02-22T10:16:03.981730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import lightgbm as lgb\n",
    "# !pip install optuna\n",
    "import optuna\n",
    "import os.path\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "class Objective():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.best_booster = None\n",
    "        self._booster = None\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        param = {\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"mean_squared_error\",\n",
    "            \"verbosity\": -1,\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"feature_fraction\": trial.suggest_loguniform(\"feature_fraction\", 0.5, 1.0),\n",
    "            \"bagging_fraction\": trial.suggest_loguniform(\"bagging_fraction\", 0.3, 1.0),\n",
    "#             \"min_gain_to_split\": trial.suggest_loguniform(\"min_gain_to_split\", 0.3, 1.0),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 400, 800),\n",
    "#             \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "#             \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 900, 2000),\n",
    "#             \"num_iterations\": trial.suggest_int(\"num_iterations\", 20, 100),\n",
    "            \"learning_rate\":trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 25),\n",
    "            \"max_bin\":trial.suggest_int(\"max_bin\", 500, 1000),\n",
    "        }\n",
    "        dtrain = lgb.Dataset(X, label=y)\n",
    "        # Add a callback for pruning.\n",
    "        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"mean_squared_error\")\n",
    "        if(os.path.isfile(\"./ubiquant-train-models/saved_models/lgbm/mdl.txt\")==True):\n",
    "            gbm=lgb.Booster(model_file=path1+\"mdl.txt\")\n",
    "            gbm = lgb.train(param, dtrain, valid_sets=[dtrain], verbose_eval=False,keep_training_booster =True,init_model=gbm)\n",
    "            gbm.save_model(path1+'mdl.txt')\n",
    "        if(os.path.isfile(\"./ubiquant-train-models/saved_models/lgbm/mdl.txt\")==False):\n",
    "            gbm = lgb.train(param, dtrain, valid_sets=[dtrain], verbose_eval=False,keep_training_booster =True)\n",
    "            gbm.save_model(path1+'mdl.txt')\n",
    "\n",
    "        self._booster = gbm\n",
    "\n",
    "        preds = gbm.predict(X)\n",
    "        pred_labels = np.rint(preds)\n",
    "        accuracy = mean_absolute_error(y, pred_labels)\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3877e471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T10:16:06.105491Z",
     "iopub.status.busy": "2022-02-22T10:16:06.104743Z",
     "iopub.status.idle": "2022-02-22T10:16:06.110835Z",
     "shell.execute_reply": "2022-02-22T10:16:06.111384Z",
     "shell.execute_reply.started": "2022-02-22T08:47:30.378088Z"
    },
    "papermill": {
     "duration": 0.026486,
     "end_time": "2022-02-22T10:16:06.111578",
     "exception": false,
     "start_time": "2022-02-22T10:16:06.085092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hyperTune(n_trials):\n",
    "    objective = Objective()\n",
    "    optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"minimize\"\n",
    "    )\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    trial_co = study.best_trial\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial_co.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "    return objective.best_booster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "024eb030",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T10:16:06.147131Z",
     "iopub.status.busy": "2022-02-22T10:16:06.146357Z",
     "iopub.status.idle": "2022-02-22T11:06:41.531710Z",
     "shell.execute_reply": "2022-02-22T11:06:41.532789Z",
     "shell.execute_reply.started": "2022-02-22T08:47:30.387013Z"
    },
    "papermill": {
     "duration": 3035.4088,
     "end_time": "2022-02-22T11:06:41.536159",
     "exception": false,
     "start_time": "2022-02-22T10:16:06.127359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "*************************\n",
      "0 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "&&&&&&&&&&&&&&&&&&&&&&\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150088\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 301\n",
      "[LightGBM] [Info] Start training from score -0.018891\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.656891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150088\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 301\n",
      "[LightGBM] [Info] Start training from score -0.018891\n",
      "***************************\n",
      "0 0.47954479861356425\n",
      "***************************\n",
      "*************************\n",
      "1 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.475710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150091\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 301\n",
      "[LightGBM] [Info] Start training from score -0.027441\n",
      "***************************\n",
      "1 0.4714211180071843\n",
      "***************************\n",
      "*************************\n",
      "2 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.559540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 136729\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.027481\n",
      "***************************\n",
      "2 0.45813920339401126\n",
      "***************************\n",
      "*************************\n",
      "3 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.487444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150096\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 301\n",
      "[LightGBM] [Info] Start training from score -0.074987\n",
      "***************************\n",
      "3 0.44363607550890366\n",
      "***************************\n",
      "*************************\n",
      "4 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.444259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149646\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 301\n",
      "[LightGBM] [Info] Start training from score -0.037423\n",
      "***************************\n",
      "4 0.3983985100473938\n",
      "***************************\n",
      "*************************\n",
      "5 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.479921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 136535\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.015982\n",
      "***************************\n",
      "5 0.4376227999831581\n",
      "***************************\n",
      "*************************\n",
      "6 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.442364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150082\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 301\n",
      "[LightGBM] [Info] Start training from score -0.017302\n",
      "***************************\n",
      "6 0.4740442056369401\n",
      "***************************\n",
      "*************************\n",
      "7 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.466019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150078\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 301\n",
      "[LightGBM] [Info] Start training from score -0.025576\n",
      "***************************\n",
      "7 0.45306426837117936\n",
      "***************************\n",
      "*************************\n",
      "8 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.451716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150075\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 301\n",
      "[LightGBM] [Info] Start training from score -0.016343\n",
      "***************************\n",
      "8 0.44733985319002606\n",
      "***************************\n",
      "*************************\n",
      "9 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.551540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150072\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 301\n",
      "[LightGBM] [Info] Start training from score -0.006600\n",
      "***************************\n",
      "9 0.4467834820448581\n",
      "***************************\n",
      "*************************\n",
      "10 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.519469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150069\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 301\n",
      "[LightGBM] [Info] Start training from score -0.015252\n",
      "***************************\n",
      "10 0.4690530071194476\n",
      "***************************\n",
      "*************************\n",
      "11 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.671056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150066\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 301\n",
      "[LightGBM] [Info] Start training from score -0.011354\n",
      "***************************\n",
      "11 0.4759700587078689\n",
      "***************************\n",
      "*************************\n",
      "12 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.544627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150067\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 301\n",
      "[LightGBM] [Info] Start training from score -0.010114\n",
      "***************************\n",
      "12 0.43895718582758825\n",
      "***************************\n",
      "*************************\n",
      "13 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.530702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150065\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 301\n",
      "[LightGBM] [Info] Start training from score -0.005779\n",
      "***************************\n",
      "13 0.4332589620955235\n",
      "***************************\n",
      "*************************\n",
      "14 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 463.87 MB\n",
      "Memory usage after optimization is: 117.11 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.547935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150063\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 301\n",
      "[LightGBM] [Info] Start training from score -0.005548\n",
      "***************************\n",
      "14 0.4371248725877913\n",
      "***************************\n",
      "*************************\n",
      "15 200000\n",
      "*************************\n",
      "Memory usage of dataframe is 327.98 MB\n",
      "Memory usage after optimization is: 82.80 MB\n",
      "Decreased by 74.8%\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.312603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150043\n",
      "[LightGBM] [Info] Number of data points in the train set: 141411, number of used features: 301\n",
      "[LightGBM] [Info] Start training from score -0.021529\n",
      "***************************\n",
      "15 0.3752043893514236\n",
      "***************************\n",
      "*************************\n",
      "16 141411\n",
      "*************************\n",
      "Memory usage of dataframe is 0.00 MB\n",
      "Memory usage after optimization is: 0.00 MB\n",
      "Decreased by nan%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import gc\n",
    "gc.enable()\n",
    "Path(\"./ubiquant-train-models/saved_models/lgbm/\").mkdir(parents=True, exist_ok=True)\n",
    "path=\"../input/ubiquant-market-prediction/train.csv\"\n",
    "path1=\"./ubiquant-train-models/saved_models/lgbm/\"\n",
    "# model=lgb.LGBMRegressor(max_depth=100,num_leaves=600,num_iterations=100, keep_training_booster=True )\n",
    "sample_size=200000\n",
    "# loop=math.ceil(insIdCt[0][0]/sample_size)\n",
    "i=0\n",
    "df=df=reduce_mem_usage(pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows  = [j for j in range(1, i*sample_size) ],nrows=sample_size))\n",
    "lgb_path=\"./lg_model/\"\n",
    "while(len(df)>0):\n",
    "    print(\"*************************\")\n",
    "    print(i,len(df))\n",
    "    print(\"*************************\")\n",
    "#     df=extractData(i*sample_size,(i*sample_size)+sample_size,path,'investment_id').toPandas()\n",
    "    df=reduce_mem_usage(pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows  = [j for j in range(1, i*sample_size) ],nrows=sample_size))\n",
    "    df_1=pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows = 0,nrows=1)\n",
    "    df.columns=df_1.columns\n",
    "    del df_1\n",
    "    if(len(df)==0):\n",
    "        break;\n",
    "    X=np.array(df.drop(['target','row_id','investment_id'],axis=1))\n",
    "    y=np.array(df['target'])\n",
    "    \n",
    "    params={\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"feature_fraction\": 0.7,\n",
    "    \"bagging_fraction\": 0.30,\n",
    "#     \"min_gain_to_split\": 0.48621442782475605,\n",
    "    \"max_depth\": 800,\n",
    "#     \"lambda_l1\": 0.03742217988743394,\n",
    "#     \"lambda_l2\": 0.20030511153917615294,\n",
    "    \"num_leaves\": 1700,\n",
    "    \"num_iterations\": 20,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 50,\n",
    "    \"max_bin\": 500}\n",
    "    dtrain = lgb.Dataset(X, label=y, free_raw_data=False)\n",
    "#     params =  hyperTune(25)\n",
    "#     gbm=lgb.Booster(model_file=path1+\"mdl.txt\")\n",
    "    gbm= lgb.LGBMRegressor(params)\n",
    "    if(i==0):\n",
    "        print(\"&&&&&&&&&&&&&&&&&&&&&&\")\n",
    "        gbm = lgb.train(params, dtrain, valid_sets=[dtrain], verbose_eval=False,keep_training_booster =True)\n",
    "        gbm.save_model(path1+'mdl.txt')\n",
    "    gbm=lgb.Booster(model_file=path1+\"mdl.txt\")\n",
    "    gbm = lgb.train(params, dtrain, valid_sets=[dtrain], verbose_eval=False,keep_training_booster =True)\n",
    "#     gbm = lgb.train(params, dtrain, valid_sets=[dtrain], verbose_eval=False,keep_training_booster =True,init_model=gbm)\n",
    "    gbm.save_model(path1+'mdl.txt')\n",
    "#     gbm = model.fit(X,y)\n",
    "    y_pred=gbm.predict(X)\n",
    "    MSE(y, y_pred)\n",
    "    print(\"***************************\")\n",
    "    print(i,MSE(pd.DataFrame(y), pd.DataFrame(y_pred)))\n",
    "    print(\"***************************\")\n",
    "    del X\n",
    "    del y\n",
    "    del dtrain\n",
    "    i+=1\n",
    "    gc.collect()\n",
    "# del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3301dc5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T11:06:41.639444Z",
     "iopub.status.busy": "2022-02-22T11:06:41.638356Z",
     "iopub.status.idle": "2022-02-22T11:06:41.917522Z",
     "shell.execute_reply": "2022-02-22T11:06:41.918225Z",
     "shell.execute_reply.started": "2022-02-22T10:02:00.763035Z"
    },
    "papermill": {
     "duration": 0.336363,
     "end_time": "2022-02-22T11:06:41.918408",
     "exception": false,
     "start_time": "2022-02-22T11:06:41.582045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "import ubiquant\n",
    "env = ubiquant.make_env()\n",
    "iter_test = env.iter_test() \n",
    "model=lgb.Booster(model_file=path1+\"mdl.txt\") \n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    sample_prediction_df['target'] = model.predict(test_df.drop(['row_id'],axis=1))\n",
    "#     sample_prediction_df\n",
    "    env.predict(sample_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc680e7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T11:06:42.014141Z",
     "iopub.status.busy": "2022-02-22T11:06:42.013067Z",
     "iopub.status.idle": "2022-02-22T11:06:42.015653Z",
     "shell.execute_reply": "2022-02-22T11:06:42.016234Z",
     "shell.execute_reply.started": "2022-02-22T10:02:01.048395Z"
    },
    "papermill": {
     "duration": 0.053808,
     "end_time": "2022-02-22T11:06:42.016426",
     "exception": false,
     "start_time": "2022-02-22T11:06:41.962618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# insIdCt=getCount(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e29ee34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T11:06:42.111330Z",
     "iopub.status.busy": "2022-02-22T11:06:42.110049Z",
     "iopub.status.idle": "2022-02-22T11:06:42.115688Z",
     "shell.execute_reply": "2022-02-22T11:06:42.115066Z",
     "shell.execute_reply.started": "2022-02-22T10:02:01.053799Z"
    },
    "papermill": {
     "duration": 0.053221,
     "end_time": "2022-02-22T11:06:42.115847",
     "exception": false,
     "start_time": "2022-02-22T11:06:42.062626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import math\n",
    "# import lightgbm as lgb\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# def generator(size1):\n",
    "# #     loop=math.ceil(insIdCt[0][0]/size1)\n",
    "#     i=0\n",
    "#     df=reduce_mem_usage(pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows = [j for j in range(1, i*size1) ],nrows=size1))\n",
    "#     while(i>=0):\n",
    "        \n",
    "#         df=reduce_mem_usage(pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows = [j for j in range(1, i*size1) ],nrows=size1))\n",
    "#         if(len(df)==0):\n",
    "#             i=-1\n",
    "#         df_1=pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\",nrows=1)\n",
    "#         df.columns=df_1.columns\n",
    "#         X=np.array(df.drop(['target','row_id'],axis=1))\n",
    "#         y=np.array(df['target'])\n",
    "#         i+=1\n",
    "# #         del df\n",
    "#         yield X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baf647b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T11:06:42.205528Z",
     "iopub.status.busy": "2022-02-22T11:06:42.204383Z",
     "iopub.status.idle": "2022-02-22T11:06:42.208072Z",
     "shell.execute_reply": "2022-02-22T11:06:42.208747Z",
     "shell.execute_reply.started": "2022-02-22T10:02:01.069410Z"
    },
    "papermill": {
     "duration": 0.050882,
     "end_time": "2022-02-22T11:06:42.208925",
     "exception": false,
     "start_time": "2022-02-22T11:06:42.158043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i=0\n",
    "# size1=20000\n",
    "# df=reduce_mem_usage(pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows = [j for j in range(1, i*size1) ],nrows=size1))\n",
    "# while(i>=0):\n",
    "#     df=reduce_mem_usage(pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\", skiprows = [j for j in range(1, i*size1) ],nrows=size1))\n",
    "#     print(len(df),i)\n",
    "#     if(len(df)==0):\n",
    "#         i=-1\n",
    "#     df_1=pd.read_csv(\"../input/ubiquant-market-prediction/train.csv\",nrows=1)\n",
    "#     df.columns=df_1.columns\n",
    "#     X=np.array(df.drop(['target','row_id'],axis=1))\n",
    "#     y=np.array(df['target'])\n",
    "#     i+=1\n",
    "# #         del df\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeaad2b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T11:06:42.298040Z",
     "iopub.status.busy": "2022-02-22T11:06:42.297053Z",
     "iopub.status.idle": "2022-02-22T11:06:42.300252Z",
     "shell.execute_reply": "2022-02-22T11:06:42.300871Z",
     "shell.execute_reply.started": "2022-02-22T10:02:01.080191Z"
    },
    "papermill": {
     "duration": 0.049441,
     "end_time": "2022-02-22T11:06:42.301043",
     "exception": false,
     "start_time": "2022-02-22T11:06:42.251602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# size1=64\n",
    "# train_generator =generator(size1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e53088f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T11:06:42.389130Z",
     "iopub.status.busy": "2022-02-22T11:06:42.388031Z",
     "iopub.status.idle": "2022-02-22T11:06:42.392620Z",
     "shell.execute_reply": "2022-02-22T11:06:42.393230Z",
     "shell.execute_reply.started": "2022-02-22T10:02:01.089359Z"
    },
    "papermill": {
     "duration": 0.050511,
     "end_time": "2022-02-22T11:06:42.393428",
     "exception": false,
     "start_time": "2022-02-22T11:06:42.342917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # import the necessary modules from the library\n",
    "# size1=128\n",
    "# train_generator =generator(size1)\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Conv2D, Flatten, Activation, LSTM, Dropout,BatchNormalization,RepeatVector\n",
    "# model = Sequential()\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(1024))\n",
    "# model.add(Dense(1024))\n",
    "# model.add(Dense(1024))\n",
    "# model.add(Activation('swish'))\n",
    "# model.add(RepeatVector(3))\n",
    "# model.add(LSTM(512, activation = 'swish', return_sequences=True))\n",
    "# # model.add(Dropout(0.3))\n",
    "# model.add(LSTM(256, activation = 'swish', return_sequences=True))\n",
    "# # model.add(Dropout(0.3))\n",
    "# model.add(Dense(1))\n",
    "# model.add(Activation('softmax'))\n",
    "# model.compile(loss='MeanSquaredError',\n",
    "#               optimizer='adam',#'rmsprop',\n",
    "#               metrics=['mean_squared_error'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d77fc47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T11:06:42.483267Z",
     "iopub.status.busy": "2022-02-22T11:06:42.482232Z",
     "iopub.status.idle": "2022-02-22T11:06:42.487100Z",
     "shell.execute_reply": "2022-02-22T11:06:42.486521Z",
     "shell.execute_reply.started": "2022-02-22T10:02:01.098564Z"
    },
    "papermill": {
     "duration": 0.051239,
     "end_time": "2022-02-22T11:06:42.487275",
     "exception": false,
     "start_time": "2022-02-22T11:06:42.436036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.fit_generator(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=size1, #// batch_size,\n",
    "#         epochs=1\n",
    "# #         validation_data=train_generator#,\n",
    "# #         validation_steps=64\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7fc2113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T11:06:42.576567Z",
     "iopub.status.busy": "2022-02-22T11:06:42.575868Z",
     "iopub.status.idle": "2022-02-22T11:06:42.580058Z",
     "shell.execute_reply": "2022-02-22T11:06:42.579384Z",
     "shell.execute_reply.started": "2022-02-22T10:02:01.111007Z"
    },
    "papermill": {
     "duration": 0.050109,
     "end_time": "2022-02-22T11:06:42.580220",
     "exception": false,
     "start_time": "2022-02-22T11:06:42.530111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a=extractData(i*5,(i*5)+5,path,'investment_id')\n",
    "# [j for j in range(1, i*size1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7336bdc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T11:06:42.670493Z",
     "iopub.status.busy": "2022-02-22T11:06:42.669438Z",
     "iopub.status.idle": "2022-02-22T11:06:42.672577Z",
     "shell.execute_reply": "2022-02-22T11:06:42.671964Z",
     "shell.execute_reply.started": "2022-02-22T10:02:01.124178Z"
    },
    "papermill": {
     "duration": 0.050111,
     "end_time": "2022-02-22T11:06:42.672748",
     "exception": false,
     "start_time": "2022-02-22T11:06:42.622637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # b=a.toPandas()[100]\n",
    "# a.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb544671",
   "metadata": {
    "papermill": {
     "duration": 0.04379,
     "end_time": "2022-02-22T11:06:42.758590",
     "exception": false,
     "start_time": "2022-02-22T11:06:42.714800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3053.109514,
   "end_time": "2022-02-22T11:06:44.654400",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-22T10:15:51.544886",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
